{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable, Function\n",
    "import inspect\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# import functools\n",
    "# TODO: Use functools.wrap to get original function/method dir attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 10\n",
    "KAPPA = 3 # ~29 bits\n",
    "\n",
    "PRECISION_INTEGRAL = 2\n",
    "PRECISION_FRACTIONAL = 5\n",
    "PRECISION = PRECISION_INTEGRAL + PRECISION_FRACTIONAL\n",
    "BOUND = BASE**PRECISION\n",
    "\n",
    "# Q field\n",
    "Q = 2**41 # < 64 bits\n",
    "#Q = 2147483648\n",
    "Q_MAXDEGREE = 1\n",
    "#assert Q > BASE**(PRECISION * Q_MAXDEGREE) # supported multiplication degree (without truncation)\n",
    "#assert Q > 2*BOUND * BASE**KAPPA # supported kappa when in positive range \n",
    "\n",
    "# P field\n",
    "P = 1802216888453791673313287943102424579859887305661122324585863735744776691801009887 # < 270 bits\n",
    "P_MAXDEGREE = 9\n",
    "#assert P > Q\n",
    "#assert P > BASE**(PRECISION * P_MAXDEGREE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(rational,field=Q,precision_fractional=PRECISION_FRACTIONAL):\n",
    "    upscaled = (rational * BASE**precision_fractional).long()\n",
    "    upscaled.remainder_(field)\n",
    "    return upscaled\n",
    "def decode(field_element,field=Q,precision_fractional=PRECISION_FRACTIONAL):\n",
    "    field_element = field_element.data\n",
    "    neg_values = field_element.gt(field)\n",
    "    #pos_values = field_element.le(field)\n",
    "    #upscaled = field_element*(neg_valuese+pos_values)\n",
    "    field_element[neg_values] = field-field_element[neg_values]\n",
    "    rational = field_element.float()/ BASE**precision_fractional\n",
    "    return rational\n",
    "def share(secret,field=Q):\n",
    "    first = torch.LongTensor(secret.shape).random_(field)\n",
    "    second = (secret - first)% field\n",
    "    return [first,second]\n",
    "def reconstruct(shares ,field=Q):\n",
    "    return sum(shares)%field\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_share(value):\n",
    "    raise NotImplementedError()\n",
    "def receive_share():\n",
    "    raise NotImplementedError()\n",
    "def swap_shares(share,party):\n",
    "    if (party == 0):\n",
    "        send_share(share)\n",
    "        share_other = receive_share()\n",
    "    elif (party == 1):\n",
    "        share_other = receive_share()\n",
    "        send_share(share)\n",
    "    return share_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def public_add(x,y,party):\n",
    "    if (party ==0):\n",
    "        return x+y\n",
    "    elif(party == 1):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mul_triple(m,n,field=Q):\n",
    "    r = torch.LongTensor(m,n).random_(field)\n",
    "    s = torch.LongTensor(m,m).random_(field)\n",
    "    t = r * s \n",
    "    return r,s,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mul_triple_communication(m,n,party,field=Q):\n",
    "    if (party==0):\n",
    "        r,s,t = generate_mul_triple(m,n,field)\n",
    "        \n",
    "        r_alice, r_bob = share(r)\n",
    "        s_alice, s_bob = share(s)\n",
    "        t_alice, t_bob = share(t)\n",
    "        \n",
    "        reponse_r = swap_shares(r_bob,party)\n",
    "        reponse_s = swap_shares(s_bob,party)\n",
    "        reponse_t = swap_shares(t_bob,party)\n",
    "        \n",
    "        triple_alice = [r_alice,s_alice,t_alice]\n",
    "        return triple_alice\n",
    "    elif (party == 1):\n",
    "        r_bob = swap_shares(torch.LongTensor(m,n).zero_(),party)\n",
    "        s_bob = swap_shares(torch.LongTensor(m,n).zero_(),party)\n",
    "        t_bob = swap_shares(torch.LongTensor(m,n).zero_(),party)\n",
    "        triple_bob = [r_bob,s_bob,t_bob]\n",
    "        return triple_bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spdz_mul(x,y,party,field=Q):\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError()\n",
    "    m,n = a.shape\n",
    "    triple = generate_mul_triple_communication(m,n,party,field)\n",
    "    a,b,c = triple\n",
    "    d = x - a\n",
    "    e = y - b\n",
    "    \n",
    "    d_other = swap_shares(d,party)\n",
    "    e_other = swap_shares(e,party)\n",
    "    delta = reconstruct([d,d_other],field)\n",
    "    epsilon = reconstruct([e,e_other],field)\n",
    "    r = delta * epsilon\n",
    "    s = a * epsilon\n",
    "    t = b * delta\n",
    "    share = s + t + c\n",
    "    share = public_add(share,r,party)\n",
    "    share = truncate(share)\n",
    "    return share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matmul_triple(m,n,k,field=Q):\n",
    "    r = torch.LongTensor(m,k).random_(field)\n",
    "    s = torch.LongTensor(k,n).random_(field)\n",
    "    t = (r @ s) % field\n",
    "    return r, s, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matmul_triple_communication(m,n,k,party,field=Q):\n",
    "    if(party ==0):\n",
    "        r,s,t = generate_matmul_triple(m,n,k,field)\n",
    "        r_alice, r_bob = share(r)\n",
    "        s_alice, s_bob = share(s)\n",
    "        t_alice, t_bob = share(t)\n",
    "        \n",
    "        reponse_r = swap_shares(r_bob,party)\n",
    "        reponse_s = swap_shares(s_bob,party)\n",
    "        reponse_t = swap_shares(t_bob,party)\n",
    "        \n",
    "        triple_alice = [r_alice,s_alice,t_alice]\n",
    "        return triple_alice\n",
    "    elif (party == 1):\n",
    "        r_bob = swap_shares(torch.LongTensor(m,k).zero_(),party)\n",
    "        s_bob = swap_shares(torch.LongTensor(k,n).zero_(),party)\n",
    "        t_bob = swap_shares(torch.LongTensor(m,n).zero_(),party)\n",
    "        triple_bob = [r_bob,s_bob,t_bob]\n",
    "        return triple_bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spdz_matmul(x,y,party,field=Q):\n",
    "    x_height = x.shape[0]\n",
    "    x_width = x.shape[1]\n",
    "    \n",
    "    y_height = y.shape[0]\n",
    "    y_width = y.shape[1]\n",
    "    \n",
    "    assert x_width == y_height\n",
    "    \n",
    "    r, s, t = generate_matmul_triple_communication(x_height,y_width,x_width, party,field)\n",
    "\n",
    "    rho_local = x - r\n",
    "    sigma_local = y - s\n",
    "    \n",
    "    # Communication\n",
    "    rho_other = swap_shares(rho_local, party, socket)\n",
    "    sigma_other = swap_shares(sigma_local, party, socket)\n",
    "    \n",
    "    # They both add up the shares locally\n",
    "    rho = reconstruct([rho_local, rho_other],field)\n",
    "    sigma = reconstruct([sigma_local, sigma_other],field)\n",
    "\n",
    "    r_sigma = r @ sigma    \n",
    "    rho_s = rho @ s \n",
    "\n",
    "    share =  r_sigma + rho_s + t \n",
    "    \n",
    "    rs = rho @ sigma\n",
    "\n",
    "    share = add_public(share, rs)\n",
    "    share = truncate(share)   \n",
    "    return share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedAdd(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b,field=Q):\n",
    "        return a+b % field\n",
    "        # compute a + b on encrypted data - they are regular PyTorch tensors\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        grad_out = VariableProxy(grad_out.data)\n",
    "        return grad_out.var,grad_out.var\n",
    "        # not grad_out operators are overloaded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedMult(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        ctx.save_for_backward(a,b)       \n",
    "        return spdz_mul(a,b,party)\n",
    "        # compute a * b on encrypted data - they are regular PyTorch tensors\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        a,b = ctx.saved_tensors\n",
    "        grad_out = grad_out\n",
    "        return Variable(spdz_mul(grad_out.data,b,party)),Variable(spdz_mul(grad_out.data,a,pary))\n",
    "        # not grad_out operators are overloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedMatmul(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx,a,b,party):\n",
    "        ctx.save_for_backward(a,b)\n",
    "        return spdz_matmul(a,b,party)\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_out,party):\n",
    "        a,b = ctx.saved_tensors\n",
    "        return spdz_matmul( grad_out,  b.t_()), spdz_matmul(grad_out , a.t_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedSigmoid(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx,a,party):\n",
    "        ctx.save_for_backwards(a)\n",
    "        return spdz_sigmoid(a)\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_out,party):\n",
    "        a = ctx.saved_tensors\n",
    "        ones = encode(torch.FloatTensor(a.shape).one_())\n",
    "        return spdz_mul(a,public_add(ones,-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableProxy(object):\n",
    "    \n",
    "    def __init__(self, var, party, field=Q, requires_grad=True):\n",
    "        self.var = Variable(var,requires_grad=requires_grad)\n",
    "        self.var = self.var\n",
    "        self.party = party\n",
    "        self.field = field\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return (EncryptedAdd.apply(self.var, other.var))\n",
    "    \n",
    "    def __mul__(self,other):\n",
    "        return (EncryptedMult.apply(self.var, other.var))\n",
    "    def __matmul__(self,other):\n",
    "        return (EncryptedMatmul.apply(self.var,other.var,self.party))\n",
    "    def sigmoid(self):\n",
    "        return(EncryptedSigmoid.apply(self.var,self.party))\n",
    "    def grad(self):\n",
    "        return self.var.grad\n",
    "    def t_():\n",
    "        self.var = self.var.t_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = VariableProxy(encode(torch.FloatTensor([[1,1,1],[1,1,3]])),1,requires_grad=True)\n",
    "y = VariableProxy(encode(torch.FloatTensor([[2,3],[4,4],[2,2]])),1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ef15786672a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-bc96be165522>\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEncryptedMult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__matmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEncryptedMatmul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-2a67032a1099>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, a, b, party)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mspdz_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dbf52e115b6e>\u001b[0m in \u001b[0;36mspdz_matmul\u001b[0;34m(x, y, party, field)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mx_width\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_matmul_triple_communication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrho_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5615492912f7>\u001b[0m in \u001b[0;36mgenerate_matmul_triple_communication\u001b[0;34m(m, n, k, party, field)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriple_alice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparty\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mr_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_shares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0ms_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_shares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mt_bob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_shares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fc65f2483a3c>\u001b[0m in \u001b[0;36mswap_shares\u001b[0;34m(share, party)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mshare_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceive_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparty\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mshare_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceive_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msend_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mshare_other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fc65f2483a3c>\u001b[0m in \u001b[0;36mreceive_share\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreceive_share\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mswap_shares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparty\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "z = x @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.0000e+05\n",
       " 4.0000e+05\n",
       " 5.0000e+05\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3\n",
       " 4\n",
       " 5\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward(torch.FloatTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
